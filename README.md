# Awesome-Quantization-Papers-For-LLM
A collection of papers on quantization techniques for large language models, compiled for easy reference and personal study.

## Overview

- "Evaluating Quantized Large Language Models", ICML, 2024. [[paper](https://openreview.net/forum?id=DKKg5EFAFr)] [**`Survey`**] [**`None`**]  [**`None`**] 
- "SqueezeLLM: Dense-and-Sparse Quantization", ICML, 2024. [[paper](https://openreview.net/forum?id=0jpbpFia8m)] [**`W`**] [**`No Fine-tuning`**] [**`Non-uniform`**]
- "KIVI: A Tuning-Free Asymmetric 2bit Quantization for KV Cache", ICML, 2024. [[paper](https://openreview.net/forum?id=L057s2Rq8O)] [**`KV`**] [**`No Fine-tuning`**] [**`Uniform`**]
- "Extreme Compression of Large Language Models via Additive Quantization", ICML, 2024. [[paper](https://openreview.net/forum?id=5mCaITRTmO)] [**`W`**] [**`to be fill`**]  [**`to be fill`**]
- "BiE: Bi-Exponent Block Floating-Point for Large Language Models Quantization", ICML, 2024. [[paper](https://openreview.net/forum?id=DbyHDYslM7)] [**`WA`**] [**`to be fill`**]  [**`to be fill`**]
- "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", ICLR, 2024. [[paper](https://openreview.net/forum?id=8Wuvhh0LYW)] [**`WA`**] [**`Fine-tuning`**] [**`Uniform`**]
